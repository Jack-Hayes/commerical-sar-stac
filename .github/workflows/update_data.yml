name: Weekly Data Update

on:
  schedule:
    # Runs at 02:00 on Sunday morning
    - cron: '0 2 * * 0'
  workflow_dispatch: # Allows manual triggering

jobs:
  update-parquet-files:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}
    permissions:
      contents: write # Allows the job to push to the repo

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Mambaforge environment
        uses: conda-incubator/setup-miniconda@v3
        with:
          python-version: "3.11"
          environment-file: environment.yml
          mamba-version: "*"
          activate-environment: commercial-sar
          auto-update-conda: true
          channel-priority: "strict"

      # Backup existing parquet files before processing
      - name: Backup existing parquet files
        run: |
          mkdir -p parquets_backup
          if [ -d "parquets" ]; then
            cp -r parquets/* parquets_backup/ || true
            echo "Backup created"
          fi

      # Run data ingestion
      - name: Run data ingestion script
        run: python -m scripts.main capella iceye umbra --format both

      # Run tests to validate new data
      - name: Run validation tests
        id: validation
        run: |
          pytest tests/test_processing.py -v
          pytest tests/test_structure.py -v
          pytest tests/test_endpoints.py -v
        continue-on-error: false

      # Only commit if tests pass
      - name: Commit and push changes
        if: success()
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Weekly data update"
          file_pattern: "parquets/**/*.parquet"
          commit_user_name: "GitHub Actions Bot"
          commit_user_email: "github-actions[bot]@users.noreply.github.com"
          commit_author: "GitHub Actions Bot <github-actions[bot]@users.noreply.github.com>"

      # Restore backup if tests failed
      - name: Restore backup on failure
        if: failure()
        run: |
          if [ -d "parquets_backup" ]; then
            rm -rf parquets
            mv parquets_backup parquets
            echo "Tests failed - backup restored"
          fi

      # Clean up backup on success
      - name: Clean up backup
        if: success()
        run: rm -rf parquets_backup

      # Create issue on failure
      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'Weekly data update failed',
              body: `The weekly data update failed on ${new Date().toISOString()}.
              
              **Workflow run:** ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}
              
              Please check the logs and verify:
              - Provider endpoints are still accessible
              - STAC item structure hasn't changed
              - Processing logic is compatible with new data
              
              The previous week's data has been preserved.`,
              labels: ['automated', 'data-update', 'needs-investigation']
            })